# ğŸ“Œ Credit Risk Classification Project

## ğŸ“– Overview
Ever wondered how banks decide whether you're a safe bet or a financial daredevil? ğŸ’°ğŸš€ This project takes on credit risk classification using machine learning, sorting customers into four risk levels: P1 (Saints) ğŸ˜‡, P2 (Cautious) ğŸ¤”, P3 (Risky) âš ï¸, and P4 (Wildcards) ğŸ². 

## ğŸ“‚ Data Processing
Like a detective hunting for clues ğŸ”, I cleaned and prepped the dataset meticulously:
- Kicked out invalid values (-99999) like unwanted guests ğŸš«
- Filled in missing data (because guessing is better than ghosting) ğŸ‘»
- Sorted categorical & numerical features like a neat freak ğŸ·ï¸
- Ran Chi-square & ANOVA tests to pick the MVP features ğŸ†
- Applied Variance Inflation Factor (VIF) to remove overly clingy, redundant variables ğŸš®
- One-hot & label encoding because machines donâ€™t speak human ğŸ­

## ğŸ—ï¸ Model Training & Evaluation
I let three ML models duke it out in the arena:

### 1ï¸âƒ£ Random Forest ğŸŒ³
- Accuracy: **76%** âœ…

### 2ï¸âƒ£ XGBoost âš¡
- Accuracy: **77%** ğŸ“ˆ
- The MVPâ€”best performer overall! ğŸ†

### 3ï¸âƒ£ Decision Tree ğŸŒ²
- Accuracy: **70%** ğŸ“‰
- Good effort, but lost to the competition ğŸ˜“

## ğŸ› ï¸ Hyperparameter Tuning
- Grid Search = The secret sauce for model optimization ğŸ”„
- Final results: **82% training accuracy** & **78% test accuracy** ğŸš€

## ğŸ’¾ Model Deployment
- Trained model saved as `model.sav` ğŸ“¥
- Training dataset stored in `training_data.csv` ğŸ“‘
- Built a **Streamlit app** (`app.py`) for fun, easy predictions ğŸ›ï¸

## ğŸ–¥ï¸ Streamlit Web App Features
- ğŸ“‚ Upload a CSV file, let the magic happen
- ğŸ¤– Automatically preprocesses & encodes data
- ğŸ“Š Predicts risk levels and displays results
- ğŸ“¥ Downloadable CSV of risk classifications

